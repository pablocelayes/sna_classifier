{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](imgs/miredtwitter_header2.png)  \n",
    "<center>\n",
    "<h1>\n",
    "Dime a quiénes sigues y te diré qué prefieres\n",
    "</h1>\n",
    "\n",
    "<h2>\n",
    "[Tell me who you follow and I'll tell you what you like]\n",
    "</h2>\n",
    "\n",
    "<h2>\n",
    "(SNA, ML and a bit of NLP)\n",
    "</h2>\n",
    "<h3>Pablo Gabriel Celayes</h3>\n",
    "<h4>November 16th, 2017 - PyData San Luis</h4>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Roadmap\n",
    "\n",
    "* Introduction\n",
    "\n",
    "* Toolkit\n",
    "\n",
    "* Dataset\n",
    "\n",
    "* Social prediction\n",
    "\n",
    "* Adding NLP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction: who am I?\n",
    "\n",
    "* Mathematician (2006)\n",
    "\n",
    "* Computer Scientist (2017)\n",
    "\n",
    "* ![](imgs/mitwitter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Introduction: what I did\n",
    "\n",
    "## Original idea\n",
    "\n",
    "- *Personalized* content-based recommender system of news articles.\n",
    "- How do we improve it with social information? ( from external sources or inferred relations )\n",
    "- Explicit preference information collected by the Cogfor platform.\n",
    "\n",
    "![](imgs/cogfor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Mutation\n",
    "\n",
    "- Build our own dataset ( users, preferences, connections ).\n",
    "- Start predicting preferences using only social information.\n",
    "- Improve using content-based features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Toolkit\n",
    "\n",
    "## Data\n",
    "![](imgs/tweepy.png)\n",
    "![](imgs/sqlalchemy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Networks\n",
    "![](imgs/networkx.png)\n",
    "![](imgs/graphtool.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data analysis\n",
    "![](imgs/numpy.png)\n",
    "![](imgs/pandas.png)\n",
    "![](imgs/jupyter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ML + NLP\n",
    "![](imgs/sklearn.png)\n",
    "![](imgs/nltk.png)\n",
    "![](imgs/gensim.png)\n",
    "![](imgs/twitterLDA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Visualization\n",
    "![](imgs/bokeh.png)\n",
    "![](imgs/gephi_small.png)\n",
    "### pyLDAvis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dataset: Social graph\n",
    "\n",
    "- up to 3 steps in the $\\texttt{follow}$ relation, starting with my own profile.\n",
    "- We consider only **relevant** users ( >40 followed/followers)\n",
    "- ~3M users\n",
    "- ~10M connections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*** First step... ***\n",
    "\n",
    "( it wouldn't be an SNA talk wihout a picture like this )\n",
    "\n",
    "![](imgs/miredtwitter.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Dataset: Content\n",
    "\n",
    "- Subgraph $G$:\n",
    "    - we start off with a small set of *seed* users\n",
    "    - for each user, we add her 50 *most affine* followed ( affinity: rate of common followed )\n",
    "    - we repeat the process until no new users are added\n",
    "    - 5180 users\n",
    "    - ~230k connections\n",
    "\n",
    "- Tweets:\n",
    "    - *timelines* between 25/8/2015 y 24/9/2015 (+ *retweets* and *favs*)\n",
    "    - 2M tweets ( 1,6M in Spanish )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Social prediction\n",
    "\n",
    "Given a user $u$, how much can we learn about the **content** they **prefer**, from what we know about the preferences of users in her **social neighborhood**.\n",
    "\n",
    "- **Content** =  _\"visible\"_ tweets in Spanish ( $T_u$ )\n",
    "- **Preferences** = retweets\n",
    "- **Neighborhood** = followed + followed-by-followed ( $E_u$ )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visible tweets\n",
    "\n",
    "* Shared by $u$ or her followed \n",
    "* We exclude those _written_ by $u$\n",
    "* maximum $10000$ ( we subsample negative examples when necessary )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## User selection\n",
    "\n",
    "* Training and evaluating models is computationally expensive\n",
    "* I'm lazy and I wanted to do everything on my laptop\n",
    "* So we pick which users to focus on for our predictions:\n",
    "    * $A$ = $1000$ most *active* (nr. of tweets)\n",
    "    * $I$ = $1000$ most *important* (Katz centrality)\n",
    "    * The lucky ones are $A \\cap I$ : $194$ users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Feature extraction\n",
    "\n",
    "* $E_u = \\{u_1, u_2, \\ldots , u_n \\}$ \n",
    "\n",
    "* $T_u = \\{ t_1, \\ldots, t_m \\}$\n",
    "\n",
    "$$\n",
    "  M_u := [ \\verb|tweet_in_tl|(t_i, u_j) ]_{\\substack{ 1 \\leq i \\leq m \\\\ 1 \\leq j \\leq n}}  \n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "  y_u := [ \\texttt{tweet_in_tl}(t_i, u) ]_{ 1 \\leq i \\leq m }  \n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Classification problem\n",
    "\n",
    "* Predict $y_u$ from the rows of $M_u$\n",
    "* Dataset split:\n",
    "    * $70\\%$ training ($M^{tr}_u, y^{tr}_u$)\n",
    "    * $10\\%$ tuning ($M^{tu}_u, y^{tu}_u$)\n",
    "    * $20\\%$ test ($M^{te}_u, y^{te}_u$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Support Vector Machines\n",
    "\n",
    "* Goal: **maximize** margin and **minimize** errors\n",
    "* Kernel functions allow to find **non-linear** decision boundaries:\n",
    "    * *Radial Basis Function*\n",
    "    * Polynomial\n",
    "\n",
    "![](imgs/svm_linsep_err.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Classification quality metric\n",
    "\n",
    "$$\\texttt{precision} := \\frac{|\\{x_i | f(x_i) = 1 \\text{ y } y_i = 1 \\}|}{|\\{x_i | f(x_i) = 1 \\}|}$$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$\\texttt{recall} := \\frac{|\\{x_i | f(x_i) = 1 \\text{ y } y_i = 1 \\}|}{|\\{x_i | y_i = 1 \\}|}$$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$\\texttt{F1} := \\frac{2}{\\frac{1}{\\texttt{precision}} + \\frac{1}{\\texttt{recall}}} = \\frac{2 * \\texttt{precision} * \\texttt{recall} }{\\texttt{precision} + \\texttt{recall}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Hyper-parameter tuning\n",
    "\n",
    "* Exhaustive search using $\\verb|GridSearchCV|$\n",
    "* $3$-fold cross validation\n",
    "* Goal: maximize $F1$\n",
    "* Grid:\n",
    "```\n",
    "{\n",
    "    \"C\": [ 0.01, 0.1, 1 ],\n",
    "    \"class_weight\": [ \"balanced\", None ], \n",
    "    \"gamma\": [ 0.1, 1, 10 ],\n",
    "    \"kernel\": [ \"rbf\", \"poly\" ]\n",
    "}\n",
    "```\n",
    "    * $C$: controls the balance between margin and error\n",
    "    * $class\\_weight$: give more importance to the minoritary (positive) class\n",
    "    * $gamma$: controls the shape of the decision boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Results\n",
    "\n",
    "* $F1$ sobre $M^{tu}_u$\n",
    "* Average $87,7 \\%$\n",
    "\n",
    "![](imgs/f1s_social_valid.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# *... and without looking at the content!*\n",
    "\n",
    "\n",
    "\n",
    "![](imgs/robot2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Adding NLP...\n",
    "\n",
    "![](imgs/robotlee.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## (Further) selection of users\n",
    "\n",
    "* $F1 < 0,75$ in $M^{tu}_u$ ( $27$ users )\n",
    "\n",
    "* ... and $10$ random users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Pre-processing\n",
    "\n",
    "- Normalization\n",
    "- Tokenization\n",
    "- Dictionary\n",
    "- *Bag of words*\n",
    "- LDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Normalization\n",
    "\n",
    "- remove URLs\n",
    "- lower case\n",
    "- remove accents\n",
    "- collapse vowel and space repetitions\n",
    "\n",
    "![](imgs/normalize.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Tokenization\n",
    "\n",
    "- separate in words\n",
    "- remover punctuation\n",
    "- _stemming_\n",
    "- remove 1-character words\n",
    "\n",
    "![](imgs/tokenize.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dictionary\n",
    "\n",
    "* Vocabulary: the whole $T$, tokenized.\n",
    "* significative ( in at least $100$ tweets ).\n",
    "* informative ( in at most $30\\%$ of $T$ ).\n",
    "\n",
    "* Dictionary $D$ with ~11K terms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## *Bag of words*\n",
    "\n",
    "- Text $t$:  $\\rightarrow$ multiset (*bag*) of $D$-terms in $t$.\n",
    "- Order is unimportant, but repetitions count.\n",
    "- For tweets ( $\\leq 140$ characters ), it's normally a *set* ( $0$ or $1$ occurrences).\n",
    "\n",
    "- We fix an order for dictionary $D = \\{ t_1, \\ldots, t_{11000} \\}$ : $\\rightarrow$ vector of integer (boolean) features:\n",
    "\n",
    "$$ v_{BOW}(tweet) = [count(t_i, tokens(tweet))]_{i=1}^{11000} $$\n",
    "\n",
    "- Sparse representation is used for $v_{BOW}(tweet)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## LDA\n",
    "\n",
    "* Discovers latent topics in a corpus of texts\n",
    "\n",
    "* Can be used as a dimensionality reduction technique ( from the space of *terms* in $D$ to a space of *topics* )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example: LDA with 10 topics\n",
    "\n",
    "![](imgs/lda10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Twitter-LDA\n",
    "\n",
    "- Problem: tweets are short and usually talk about a single topic.\n",
    "\n",
    "- Adaptations: \n",
    "    - Group all tweets from a user, and treat them as document.\n",
    "    - Assign just one topic per tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Evaluating on $M_u^{te}$\n",
    "\n",
    "![](imgs/f1s_social_vs_socialldas.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Best model: $\\texttt{TwitterLDA10}$ ( average uplift of $1,7\\%$)\n",
    "* NLP is not improving a lot for now.\n",
    "* Many cases improve in *train* but they get worse on *test* (*overfitting*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Next steps?\n",
    "\n",
    "- Fix overfitting in Social+NLP models\n",
    "\n",
    "- Take temporality into account\n",
    "\n",
    "- More features!\n",
    "\n",
    "- Generalize ( models that do not depend on a fixed central user )\n",
    "\n",
    "- _Retweetability_ in communities ( in progress )\n",
    "\n",
    "- Word embeddings?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thank you!\n",
    "\n",
    "**Code** https://github.com/pablocelayes/sna_classifier/tree/micai_datos2015\n",
    "\n",
    "**Thesis (Spanish)** https://www.dropbox.com/preview/Public/tesisSNA.pdf\n",
    "\n",
    "**Paper (English)** https://www.dropbox.com/preview/Public/retweet_prediction_micai_2017.pdf\n",
    "\n",
    "**Twitter**: @PCelayes"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
