{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from experiments._1_one_user_learn_neighbours.try_some_users import *\n",
    "from experiments.utils import *\n",
    "from experiments.datasets import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('nlp_users.json') as f:\n",
    "    users = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uid, f = users[0]; uid = int(uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test, y_train, y_valid, y_test = load_small_validation_dataframe(uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "s = open_session()\n",
    "\n",
    "train_tweets = [s.query(Tweet).get(twid) for twid in X_train.index]\n",
    "\n",
    "valid_tweets = [s.query(Tweet).get(twid) for twid in X_valid.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load TFIDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tfidf.pickle', 'rb') as f:\n",
    "    tfidf = pickle.load(f)\n",
    "\n",
    "with open('vec.pickle', 'rb') as f:\n",
    "    vec = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## explore tfidf features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "text = train_tweets[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tvec = tfidf.transform(vec.transform([text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'benitez': 9.3488612099248005,\n",
       " u'chifl': 10.000623174321891,\n",
       " u'com': 3.9209992607677515,\n",
       " u'cop': 6.8913209318308208,\n",
       " u'francozag': 9.5006672227928046,\n",
       " u'gan': 5.131842099977459,\n",
       " u'mal': 5.482071322181886,\n",
       " u'q': 4.5618390609527459,\n",
       " u'segu': 5.7053622465713012,\n",
       " u'suert': 7.1193012519456449,\n",
       " u'vas': 6.6502450410559488,\n",
       " u'x': 5.4076897147822374}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tfidf_feats(text):\n",
    "    tvec = tfidf.transform(vec.transform([text]))\n",
    "\n",
    "    ivocab = {i: w for (w,i) in vec.vocabulary_.items()}\n",
    "\n",
    "    return dict(zip([ivocab[i] for i in tvec.indices], tfidf.idf_[tvec.indices]))\n",
    "\n",
    "tfidf_feats(train_tweets[0].text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Generate TFIDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train_f = tfidf.transform(vec.transform([t.text for t in train_tweets]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_valid_f = tfidf.transform(vec.transform([t.text for t in valid_tweets]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500, 8067)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 8067)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# fname = join(DATASETS_FOLDER, \"tfidf_%d.pickle\" % uid)\n",
    "# dataset = (X_train, X_test, y_train, y_test)\n",
    "# pickle.dump(dataset, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# dataset = pickle.load(open(fname, 'rb'))\n",
    "# X_train, X_test, y_train, y_test = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import vstack\n",
    "\n",
    "\n",
    "def scale(X_train, X_test):\n",
    "    train_size = X_train.shape[0]\n",
    "    X = np.concatenate((X_train.todense(), X_test.todense()))\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train = X[:train_size,:]\n",
    "    X_test = X[train_size:,:]\n",
    "\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## class balancing sample weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# weights for class balancing\n",
    "w1 = sum(y_train)/len(y_train)\n",
    "w0 = 1 - w1\n",
    "sample_weights = np.array([w0 if x==0 else w1 for x in y_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "X_train_combined = sp.hstack((X_train,X_train_f), format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_valid_combined = sp.hstack((X_valid,X_valid_f), format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_combined, X_valid_combined = scale(X_train_combined, X_valid_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed classification report:\n",
      "\n",
      "Scores on training set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      3358\n",
      "        1.0       1.00      1.00      1.00       142\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3500\n",
      "\n",
      "Scores on test set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.93      0.95       485\n",
      "        1.0       0.08      0.20      0.11        15\n",
      "\n",
      "avg / total       0.95      0.91      0.93       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_jobs=-1, n_estimators=50)     \n",
    "clf.fit(X_train_combined, y_train, sample_weight=sample_weights)\n",
    "evaluate_model(clf, X_train_combined, X_valid_combined, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds_comb = (X_train_combined, X_valid_combined, y_train, y_valid)\n",
    "# comb_clf = model_select_svc(ds_comb, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed classification report:\n",
      "\n",
      "Scores on training set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      1.00      0.98      3358\n",
      "        1.0       1.00      0.01      0.03       142\n",
      "\n",
      "avg / total       0.96      0.96      0.94      3500\n",
      "\n",
      "Scores on test set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.98       485\n",
      "        1.0       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.94      0.97      0.96       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(**{'kernel': 'rbf', 'C': 1, 'gamma': 0.1, 'class_weight': 'balanced'})\n",
    "clf.fit(X_train_combined, y_train, sample_weight=sample_weights)\n",
    "evaluate_model(clf, X_train_combined, X_valid_combined, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186998381"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
