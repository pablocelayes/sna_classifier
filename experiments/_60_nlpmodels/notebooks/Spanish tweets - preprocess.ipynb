{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching to API Credentials #1\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import operator\n",
    "import re\n",
    "import gc\n",
    "import gensim\n",
    "\n",
    "from tw_dataset.dbmodels import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TM_MODELS_PATH = '/media/pablo/data/Tesis/models/old/tm_feats/'\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "s = open_session()\n",
    "all_tweets_es = [t for t in s.query(Tweet).all() if t.lang == 'es']\n",
    "all_tweets_text_es = [t.text for t in all_tweets_es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_tweets_es_ids = [t.id for t in all_tweets_es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1636480"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tweets_text_es)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# corpus = sample(all_tweets_text_es, 5000)\n",
    "corpus = all_tweets_text_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess(doc):\n",
    "    pre_doc = doc\n",
    "        \n",
    "    # remover URLs\n",
    "    pre_doc = re.sub(\n",
    "        r\"https?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\",\n",
    "        \" \", pre_doc)\n",
    "    \n",
    "    # minúsculas\n",
    "    pre_doc = pre_doc.lower()\n",
    "\n",
    "    # volar acentos\n",
    "    pre_doc = gensim.utils.deaccent(pre_doc)\n",
    "\n",
    "    # remove bullshit\n",
    "    pre_doc = re.sub(r\"\\@|\\'|\\\"|\\\\|…|\\/|\\-|\\||\\(|\\)|\\.|\\,|\\!|\\?|\\:|\\;|“|”|’|—\", \" \", pre_doc)\n",
    "    \n",
    "    # contraer vocales\n",
    "    for v in 'aeiou':\n",
    "        pre_doc = re.sub(r\"[%s]+\" % v, v, pre_doc)    \n",
    "    \n",
    "    # normalizar espacio en blanco\n",
    "    pre_doc = re.sub(r\"\\s+\", \" \", pre_doc)\n",
    "    pre_doc = re.sub(r\"(^\\s)|(\\s$)\", \"\", pre_doc)\n",
    "    \n",
    "    return pre_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.data import load\n",
    "from nltk.stem import SnowballStemmer\n",
    "from string import punctuation\n",
    "\n",
    "spanish_tokenizer = load('tokenizers/punkt/spanish.pickle')\n",
    "\n",
    "# stopwords en español\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "\n",
    "# spanish stemmer\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "\n",
    "# punctuation to remove\n",
    "non_words = list(punctuation)\n",
    "\n",
    "# we add spanish punctuation\n",
    "non_words.extend(['¿', '¡'])\n",
    "non_words.extend(map(str, range(10)))\n",
    "\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "\n",
    "def trystem(t):\n",
    "    try:\n",
    "        t = stemmer.stem(t)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return t\n",
    "\n",
    "def tokenize(text, stem=True, remove_stopwords=False):\n",
    "    text = text.lower()\n",
    "    result = []\n",
    "    \n",
    "    for sentence in spanish_tokenizer.tokenize(text):\n",
    "        # remover puntuación\n",
    "        text = ''.join([c for c in sentence if c not in non_words])\n",
    "        \n",
    "        # tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        if remove_stopwords:\n",
    "            tokens = [t for t in tokens if t not in spanish_stopwords]\n",
    "\n",
    "        # tokens de al menos 2 letras\n",
    "        tokens = [t for t in tokens if len(t) > 1]\n",
    "            \n",
    "        # stem\n",
    "        if stem:\n",
    "            tokens = [trystem(t) for t in tokens]\n",
    "        \n",
    "        result += tokens\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class get_docs(object):\n",
    "    def __init__(self, corpus):\n",
    "        self.corpus = corpus\n",
    "\n",
    "    def __iter__(self):\n",
    "        for doc in self.corpus:\n",
    "            tokens = tokenize(preprocess(doc), remove_stopwords=True)\n",
    "            yield tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# from gensim.models.phrases import Phraser, Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# phrases = Phrases(get_docs(corpus), min_count=5)\n",
    "# bigram = Phraser(phrases)\n",
    "# trigram = Phrases(bigram[get_docs(corpus)], min_count=5)\n",
    "# dictionary = gensim.corpora.Dictionary(trigram[get_docs(corpus)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(get_docs(corpus))\n",
    "dictionary.filter_extremes(no_below=100, no_above=0.3, keep_n=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'zocal', 11237),\n",
       " (u'podr', 11236),\n",
       " (u'coleccion', 11235),\n",
       " (u'chiquitit', 11234),\n",
       " (u'heidi', 11233),\n",
       " (u'experient', 11232),\n",
       " (u'antigued', 11231),\n",
       " (u'upahs', 11230),\n",
       " (u'santiag', 11229),\n",
       " (u'paritari', 11228),\n",
       " (u'gan', 11227),\n",
       " (u'paaristizabal', 11226),\n",
       " (u'torpez', 11225),\n",
       " (u'junt', 11224),\n",
       " (u'rellen', 11223),\n",
       " (u'kindl', 11222),\n",
       " (u'venci', 11221),\n",
       " (u'caciqu', 11220),\n",
       " (u'lanch', 11219),\n",
       " (u'peluqueri', 11218),\n",
       " (u'chavez', 11217),\n",
       " (u'juni', 11216),\n",
       " (u'palmir', 11215),\n",
       " (u'daliagutmann', 11214),\n",
       " (u'rial', 11213),\n",
       " (u'escriban', 11212),\n",
       " (u'mayweath', 11211),\n",
       " (u'infect', 11210),\n",
       " (u'volviendoacas', 11209),\n",
       " (u'pashkus', 11208),\n",
       " (u'vascarisnavarr', 11207),\n",
       " (u'chocolat', 11206),\n",
       " (u'aplic', 11205),\n",
       " (u'diplomat', 11204),\n",
       " (u'leandr', 11203),\n",
       " (u'cuelg', 11202),\n",
       " (u'kingmob', 11201),\n",
       " (u'cuell', 11200),\n",
       " (u'necesitari', 11199),\n",
       " (u'convencion', 11198),\n",
       " (u'fabiomb', 11197),\n",
       " (u'desvel', 11196),\n",
       " (u'consecuent', 11195),\n",
       " (u'bdlvictorhugoc', 11194),\n",
       " (u'ucr', 11193),\n",
       " (u'juguet', 11192),\n",
       " (u'block', 11191),\n",
       " (u'mjuanr', 11190),\n",
       " (u'ristomejid', 11189),\n",
       " (u'adriandelu', 11188)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(dictionary.token2id.items(), key=lambda x:-x[1])[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary.load(join(TM_MODELS_PATH,\"tweets_es.dict\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11238"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary.dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary.save(join(TM_MODELS_PATH,\"tweets_es.dict\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bow = [dictionary.doc2bow(doc) for doc in get_docs(corpus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(join(TM_MODELS_PATH,'tweets_es_bow.pickle'), 'wb') as f:\n",
    "    pickle.dump(bow,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
