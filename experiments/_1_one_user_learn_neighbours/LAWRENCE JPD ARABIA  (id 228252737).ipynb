{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/.virtualenvs/tesiscomp/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/pablo/.virtualenvs/tesiscomp/local/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching to API Credentials #5\n"
     ]
    }
   ],
   "source": [
    "from experiments._1_one_user_learn_neighbours.try_some_users import *\n",
    "from experiments.utils import *\n",
    "from experiments.datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uid = 228252737\n",
    "s = open_session()\n",
    "user_ld = s.query(User).get(uid)\n",
    "# X_train, X_test, y_train, y_test = load_or_create_dataset(uid)\n",
    "X_train, X_test, y_train, y_test = load_or_create_dataframe(uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neighbours = get_neighbourhood(uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2871"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_ld.timeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForestClassifier\n",
      "Detailed classification report:\n",
      "\n",
      "Scores on training set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00    165770\n",
      "        1.0       1.00      0.84      0.91      2019\n",
      "\n",
      "avg / total       1.00      1.00      1.00    167789\n",
      "\n",
      "Scores on test set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00     71058\n",
      "        1.0       0.97      0.81      0.88       852\n",
      "\n",
      "avg / total       1.00      1.00      1.00     71910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_class = RandomForestClassifier\n",
    "\n",
    "# weights for class balancing\n",
    "w1 = sum(y_train)/len(y_train)\n",
    "w0 = 1 - w1\n",
    "sample_weights = np.array([w0 if x==0 else w1 for x in y_train])\n",
    "\n",
    "print(\"Training %s\" % clf_class.__name__)\n",
    "clf = clf_class()     \n",
    "clf.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "y_true, y_pred = y_train, clf.predict(X_train)\n",
    "\n",
    "print(\"Detailed classification report:\\n\")\n",
    "print(\"Scores on training set.\\n\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(\"Scores on test set.\\n\")\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analicemos las probabilidades para tener una idea de la ¿perplejidad? del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71881.8269124\n",
      "71910.0\n"
     ]
    }
   ],
   "source": [
    "maxprobs = []\n",
    "probas = clf.predict_proba(X_test)\n",
    "for r in probas:\n",
    "    maxprobs.append(max(r))\n",
    "\n",
    "print sum(maxprobs)\n",
    "\n",
    "print probas.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este usuario muestra un recall mucho más bajo que los demás.\n",
    "Esta pérdida de calidad puede deberse a errores forzosos causados por ambigüedades en el dataset de entrenamiento.\n",
    "Diremos que hay ambigüedad para un vector de features $v$ si $(v,0)$ y $(v,1)$ ocurren ambos una cantidad significativa de veces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "miss_clf_counts, details = count_doomed_samples(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([u'Linyera'], {0.0: 1265, 1.0: 27}),\n",
       " ([u'D\\xe9bora '], {0.0: 1241, 1.0: 27}),\n",
       " ([u'Daniel Ventura'], {0.0: 749, 1.0: 8}),\n",
       " ([u'Carlos Russo'], {0.0: 297, 1.0: 7}),\n",
       " ([u'Laprogre Quespera'], {0.0: 781, 1.0: 7}),\n",
       " ([u'infobae'], {0.0: 1832, 1.0: 6}),\n",
       " ([u'EmmaDLRS\\u270c'], {0.0: 584, 1.0: 6}),\n",
       " ([u'Aldo Ulises Jarma'], {0.0: 376, 1.0: 6}),\n",
       " ([u'Pol\\xedtica Argentina'], {0.0: 421, 1.0: 6}),\n",
       " ([u'Mauricio Macri'], {0.0: 52, 1.0: 5}),\n",
       " ([u'Todo Negativo'], {0.0: 463, 1.0: 5}),\n",
       " ([u'Super Secretario'], {0.0: 270, 1.0: 5}),\n",
       " ([u'  Helena'], {0.0: 260, 1.0: 5}),\n",
       " ([u'gem'], {0.0: 849, 1.0: 4}),\n",
       " ([u'\\u049aari\\u0438oOlgoDesakatado'], {0.0: 1476, 1.0: 4}),\n",
       " ([u'Wakje'], {0.0: 1219, 1.0: 4}),\n",
       " ([u'Silvio \\xae'], {0.0: 1639, 1.0: 3}),\n",
       " ([u'6-7-8'], {0.0: 605, 1.0: 3}),\n",
       " ([u'Alex Freyre'], {0.0: 415, 1.0: 3}),\n",
       " ([u'#\\u5de8\\u5927\\u30ea\\u30d0\\u30fc\\u30d7\\u30ec\\u30fc\\u30c8'],\n",
       "  {0.0: 1235, 1.0: 3}),\n",
       " ([u'laura amado'], {0.0: 77, 1.0: 3}),\n",
       " ([u'pedro garcia'], {0.0: 214, 1.0: 3}),\n",
       " ([u'guillermo dibaja'], {0.0: 940, 1.0: 3}),\n",
       " ([u'camilogarcia'], {0.0: 351, 1.0: 3}),\n",
       " ([u'Ernest Scribbler'], {0.0: 1242, 1.0: 3}),\n",
       " ([u'hern\\xe1n pablo'], {0.0: 950, 1.0: 3}),\n",
       " ([u'Casa Rosada'], {0.0: 96, 1.0: 2}),\n",
       " ([u'CN23'], {0.0: 428, 1.0: 2}),\n",
       " ([u'Gladys Ramos'], {0.0: 137, 1.0: 2}),\n",
       " ([u'Fernando Amato'], {0.0: 685, 1.0: 2})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float, {0: 7.5, 1: 301.5})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_clf_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las ambigüedades parecen venir mayormente de retweets a usuarios con las siguientes características:\n",
    "\n",
    "* La mayoría de sus tweets no son retweeteados por LD.\n",
    "* pocos seguidores en el vecindario de LD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_sources = [d for d in details if d[1][1.0] >= 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos si realmente estos usuarios tienen tan pocos seguidores en el entorno de LD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unames = [x[0][0] for x in error_sources]\n",
    "users = {u.username: u for u in neighbours if u.username in unames}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = load_nx_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = open_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "followers = []\n",
    "nids = [u.id for u in neighbours]\n",
    "for un in unames: # importance order\n",
    "    fs = get_followers(users[un], s, g)\n",
    "    fs = [f for f in fs if f.id in nids]\n",
    "    followers.append((un, fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Linyera', 26),\n",
       " (u'D\\xe9bora ', 1),\n",
       " (u'Daniel Ventura', 16),\n",
       " (u'Carlos Russo', 14),\n",
       " (u'Laprogre Quespera', 1),\n",
       " (u'infobae', 2),\n",
       " (u'EmmaDLRS\\u270c', 1),\n",
       " (u'Aldo Ulises Jarma', 27),\n",
       " (u'Pol\\xedtica Argentina', 46),\n",
       " (u'Mauricio Macri', 15),\n",
       " (u'Todo Negativo', 60),\n",
       " (u'Super Secretario', 138),\n",
       " (u'  Helena', 3)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "follower_counts = [(un, len(fs)) for (un, fs) in followers]\n",
    "follower_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parecen tener más seguidores de lo esperado en el entorno. Veamos si estos seguidores retweetean sus tweets o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tl_counts = defaultdict(int)\n",
    "for t in user_ld.timeline:\n",
    "    tl_counts[t.author_id] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1209"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tl_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2871"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_ld.timeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contar_retweets(user, followers):\n",
    "    count = 0\n",
    "    for f in followers:\n",
    "        rts = [t for t in f.timeline if t.author_id == user.id]\n",
    "        count += len(rts)\n",
    "    return count  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt_counts = {}\n",
    "for un in unames:\n",
    "    user = users[un]\n",
    "    rt_counts[un] = contar_retweets(user, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'  Helena': 0,\n",
       " u'Aldo Ulises Jarma': 0,\n",
       " u'Carlos Russo': 0,\n",
       " u'Daniel Ventura': 0,\n",
       " u'D\\xe9bora ': 0,\n",
       " u'EmmaDLRS\\u270c': 0,\n",
       " u'Laprogre Quespera': 0,\n",
       " u'Linyera': 0,\n",
       " u'Mauricio Macri': 0,\n",
       " u'Pol\\xedtica Argentina': 0,\n",
       " u'Super Secretario': 0,\n",
       " u'Todo Negativo': 1,\n",
       " u'infobae': 0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(twids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tws = s.query(Tweet).filter(Tweet.id.in_(twids))\n",
    "[t.text for t in tws[:10]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
