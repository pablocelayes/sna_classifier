{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cpu\n"
     ]
    }
   ],
   "source": [
    "from experiments.datasets import *\n",
    "import torch\n",
    "from os import listdir\n",
    "from torch_geometric.data import Data\n",
    "# Install required packages.\n",
    "import os\n",
    "import torch\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading user graph\n",
      "Loading pre-computed centralities\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading user graph\")\n",
    "g = load_ig_graph()\n",
    "\n",
    "fname = \"../../../centralities.pickle\"\n",
    "print(\"Loading pre-computed centralities\")\n",
    "with open(fname, 'rb') as f:\n",
    "    centralities = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATAFRAMES_PATH = \"/users/pcelayes/repos/sna_classifier/data/dataframes\"\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "train_samples = {}\n",
    "test_samples = {}\n",
    "\n",
    "for fname in listdir(DATAFRAMES_FOLDER):\n",
    "    df_path = join(DATAFRAMES_FOLDER, fname)\n",
    "    if fname.count(\"_\") > 1:\n",
    "        continue\n",
    "    if fname.startswith(\"dfXtrain_\"):\n",
    "        user_id = fname.split(\".\")[0].split(\"_\")[-1]\n",
    "        if not user_id:\n",
    "            continue\n",
    "        Xy_train = pd.read_pickle(df_path)\n",
    "        train_samples[user_id] = Xy_train.index.values.tolist()\n",
    "    elif fname.startswith(\"dfXtest_\"):\n",
    "        if not user_id:\n",
    "            continue\n",
    "        user_id = fname.split(\".\")[0].split(\"_\")[-1]\n",
    "        Xy_test = pd.read_pickle(df_path)\n",
    "        test_samples[user_id] = Xy_test.index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4662"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4662"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('781293',\n",
       " [637358147288571904,\n",
       "  637328670911295489,\n",
       "  637312767419092992,\n",
       "  642115562596925440,\n",
       "  642302593499308032,\n",
       "  643123742529441792,\n",
       "  643846692375273479,\n",
       "  642399265898242048,\n",
       "  642026192057536512,\n",
       "  641811542988713984,\n",
       "  641879116829065217,\n",
       "  641250524428410880,\n",
       "  637098873475960832,\n",
       "  636924188784242689,\n",
       "  636856587412488192,\n",
       "  637087969413890048,\n",
       "  637087172210896896,\n",
       "  644295594421420032,\n",
       "  636512739075170304,\n",
       "  636337247638437888,\n",
       "  636335698665205760,\n",
       "  636332617223270400,\n",
       "  636333398768898048,\n",
       "  636277718666084352,\n",
       "  636276285875036160,\n",
       "  637234718556200960,\n",
       "  637201723661152256,\n",
       "  637048015660941312,\n",
       "  637715920929062913,\n",
       "  637667083145322496,\n",
       "  637666490087555072,\n",
       "  642267175034744833,\n",
       "  636561383082041344,\n",
       "  642062333653708800,\n",
       "  636364605502169089,\n",
       "  642050438649417728,\n",
       "  637093772438978561,\n",
       "  644183774578786304,\n",
       "  644183354246590464,\n",
       "  637025779373707265,\n",
       "  637004149389946880,\n",
       "  636939165620391936,\n",
       "  636899478709137408,\n",
       "  644126931668103168,\n",
       "  636025395222024192,\n",
       "  637013525928538112,\n",
       "  637013061090574336,\n",
       "  637005746337652736,\n",
       "  636989927390072832,\n",
       "  636574848257499136,\n",
       "  636558773268676608,\n",
       "  641393255486197761,\n",
       "  637447742625837056,\n",
       "  637447042957209600,\n",
       "  641393109461549056,\n",
       "  637410961352224768,\n",
       "  637404102096486400,\n",
       "  641085859752738816,\n",
       "  641078251830542336,\n",
       "  642692466701897733,\n",
       "  642517632529379328,\n",
       "  642003716581781504,\n",
       "  641954581883318272,\n",
       "  644042577327583233,\n",
       "  643822028517175296,\n",
       "  643575084079292416,\n",
       "  643574031254466560,\n",
       "  643521129236275200,\n",
       "  636171742935941120,\n",
       "  635999012168970240,\n",
       "  636005569518768128,\n",
       "  640990993815347201,\n",
       "  640983083529957376,\n",
       "  640968468947435520,\n",
       "  640968192102387713,\n",
       "  636291524343562240,\n",
       "  636176413490573312,\n",
       "  641914895085268992,\n",
       "  643420630180855809,\n",
       "  643420520785014785,\n",
       "  643133174583832576,\n",
       "  643115735997358080,\n",
       "  643055299910234112,\n",
       "  642846770180059137,\n",
       "  635967919747432450,\n",
       "  635943114658607104,\n",
       "  640880653958008832,\n",
       "  636171737323991040,\n",
       "  636169722887806976,\n",
       "  636169323460079616,\n",
       "  636134704148643840,\n",
       "  642757921726681088,\n",
       "  642507846815453185,\n",
       "  642362132533747713,\n",
       "  642331055383572480,\n",
       "  641890469476216832,\n",
       "  641854913576878080,\n",
       "  641854184392892417,\n",
       "  641876322445299712,\n",
       "  641704461912670208,\n",
       "  639459629760671744,\n",
       "  635856710050160640,\n",
       "  638802041968660480,\n",
       "  638815350193303552,\n",
       "  635799611546857472,\n",
       "  638346194087972864,\n",
       "  637340190353309696,\n",
       "  635782903075590144,\n",
       "  637360973758775296,\n",
       "  636988136749441025,\n",
       "  640174909117874176,\n",
       "  640174262016442368,\n",
       "  640169520586444801,\n",
       "  636030277479985152,\n",
       "  644041145866129408,\n",
       "  638001751354945536,\n",
       "  637995366563115008,\n",
       "  637958066558922752,\n",
       "  637917798988140544,\n",
       "  638611898536169472,\n",
       "  642264105567559680,\n",
       "  638599195486756864,\n",
       "  638443418935537664,\n",
       "  642221912773525504,\n",
       "  638543680907943936,\n",
       "  641792030201417728,\n",
       "  643886457497735168,\n",
       "  643886337318330368,\n",
       "  641866720811089920,\n",
       "  643883894840950784,\n",
       "  641629450308853760,\n",
       "  641860432458842115,\n",
       "  641853365773799424,\n",
       "  637317592584208384,\n",
       "  643845664934334465,\n",
       "  641016960155840512,\n",
       "  641983781096787968,\n",
       "  641658206901673984,\n",
       "  641657399359733760,\n",
       "  638994849094627328,\n",
       "  637176070878437376,\n",
       "  637153917302894592,\n",
       "  641629668353933312,\n",
       "  641627400208580608,\n",
       "  639404465678909442,\n",
       "  636912467352887296,\n",
       "  641590659019882496,\n",
       "  638782141338361856,\n",
       "  644228792173633536,\n",
       "  644217970613428225,\n",
       "  639078586041921536,\n",
       "  641929891756277760,\n",
       "  641916807213879296,\n",
       "  641891404550131712,\n",
       "  637350218393067520,\n",
       "  641705185354608641,\n",
       "  644078303272398848,\n",
       "  637289828837625856,\n",
       "  644060934063980544,\n",
       "  637287307360497665,\n",
       "  641679519183708160,\n",
       "  637283529139875840,\n",
       "  641676724930015232,\n",
       "  644047093464723456,\n",
       "  641673159675088896,\n",
       "  644037278688497664,\n",
       "  637746659636736000,\n",
       "  637712227303301124,\n",
       "  638344564303110144,\n",
       "  638190847205462016,\n",
       "  637692473352015872,\n",
       "  643836020371423232,\n",
       "  637234814551240704,\n",
       "  637203771320369152,\n",
       "  637173133229862912,\n",
       "  636975616231895042,\n",
       "  636957956953755648,\n",
       "  643852827589222400,\n",
       "  643611297356075008,\n",
       "  643851286476144640,\n",
       "  636810129367781376,\n",
       "  639149289185374212,\n",
       "  639107268768886788,\n",
       "  638867657836634116,\n",
       "  643823369188716544,\n",
       "  638843495730577408,\n",
       "  638793369641177088,\n",
       "  643788637314924545,\n",
       "  643783105459916801,\n",
       "  643017598674862080,\n",
       "  643094361299906561,\n",
       "  643491428153327616,\n",
       "  642807269676163073,\n",
       "  642426389837271040,\n",
       "  643059188604792833,\n",
       "  644166382100312064,\n",
       "  644163869695475712,\n",
       "  644156818818732036,\n",
       "  644150023064842240,\n",
       "  644134415828938752,\n",
       "  644134167261880320,\n",
       "  641567756375212032,\n",
       "  641550140910792704,\n",
       "  643488193170526208,\n",
       "  636900058013794304,\n",
       "  636889976718929921,\n",
       "  636684425854611457,\n",
       "  637249553847185408,\n",
       "  638684893678059521,\n",
       "  638714592248659968,\n",
       "  637203846088028160,\n",
       "  639476686770319360,\n",
       "  639209361223626752,\n",
       "  636523263225675776,\n",
       "  635921914884673537,\n",
       "  643009897362292736,\n",
       "  637710636739375104,\n",
       "  637707659660165120,\n",
       "  637624808935714816,\n",
       "  637623725270110208,\n",
       "  637620302034415616,\n",
       "  643478019290611712,\n",
       "  643235511096725504,\n",
       "  636512358639226880,\n",
       "  636507824995045376,\n",
       "  636355868188127232,\n",
       "  635795651087978496,\n",
       "  637707852216442880,\n",
       "  638478509720080384,\n",
       "  637183975514095616,\n",
       "  637183113454600192,\n",
       "  637182359931105280,\n",
       "  642667220280168448,\n",
       "  637609466339459072,\n",
       "  637606503076245504,\n",
       "  637490938215038976,\n",
       "  636218270505402368,\n",
       "  637592113199345664,\n",
       "  637588053456986112,\n",
       "  643199515533660160,\n",
       "  643197639341789185,\n",
       "  643197468918841344,\n",
       "  638730112582701056,\n",
       "  638400356595167232,\n",
       "  638365148005171200,\n",
       "  637478357249212416,\n",
       "  638694573770936320,\n",
       "  638675701336526848,\n",
       "  637402719314149377,\n",
       "  637368006880940032,\n",
       "  638658237903056896,\n",
       "  638657874470785024,\n",
       "  637358660285542400,\n",
       "  638645032086577153,\n",
       "  637325489435201536,\n",
       "  637312848117518336,\n",
       "  642665520014229504,\n",
       "  636154533165563904,\n",
       "  636153505946931200,\n",
       "  638389568035815424,\n",
       "  635788699029110784,\n",
       "  635958912370507776,\n",
       "  635942336782925824,\n",
       "  635933481105797120,\n",
       "  635874847797723137,\n",
       "  643175127874695168,\n",
       "  643174716312784896,\n",
       "  643161646467313664,\n",
       "  643158167237619712,\n",
       "  643156286469709826,\n",
       "  643700815073558528,\n",
       "  637240346532016129,\n",
       "  637202597162676224,\n",
       "  643574993473900544,\n",
       "  638308171833057280,\n",
       "  638321031850106880,\n",
       "  638132434891096065,\n",
       "  642650798460174340,\n",
       "  642647749138251776,\n",
       "  642609040812605440,\n",
       "  637305725568557056,\n",
       "  637288649382600704,\n",
       "  637285136468439040,\n",
       "  642419603533074434,\n",
       "  642403736648814593,\n",
       "  642398718541602816,\n",
       "  643150473982312448,\n",
       "  643125583111700480,\n",
       "  643095110834593792,\n",
       "  643088597038571520,\n",
       "  637053264291332097,\n",
       "  635855868333002752,\n",
       "  635836993059037184,\n",
       "  637015259925086208,\n",
       "  635783905287782400,\n",
       "  636957770739228672,\n",
       "  636941575973654528,\n",
       "  638340748543414272,\n",
       "  638340495048114178,\n",
       "  638306523316396032,\n",
       "  644189077915480064,\n",
       "  638280595198578688,\n",
       "  638120516331663360,\n",
       "  638112745217392641,\n",
       "  637965546437378048,\n",
       "  637958795952566273,\n",
       "  640883363767812096,\n",
       "  635878423156686849,\n",
       "  637130374020136960,\n",
       "  636673411712987136,\n",
       "  637102098996457473,\n",
       "  637101776022413312,\n",
       "  642413824784629760,\n",
       "  638804764445310978,\n",
       "  638791464256958464,\n",
       "  642206194145304576,\n",
       "  643701099086671872,\n",
       "  638720505869127681,\n",
       "  642059567698976768,\n",
       "  642053709934030849,\n",
       "  636932466595512321,\n",
       "  638214726519009281,\n",
       "  638146789539876864,\n",
       "  643074855567499264,\n",
       "  643073780781293569,\n",
       "  635884986609074176,\n",
       "  644214864098000897,\n",
       "  637947257309036544,\n",
       "  637759254057906176,\n",
       "  643872943383121920,\n",
       "  637712861406580736,\n",
       "  637712348506140672,\n",
       "  595933123994591232,\n",
       "  636931433584586753,\n",
       "  636930160340664320,\n",
       "  643778333587718144,\n",
       "  642390752794935296,\n",
       "  643761713439985664,\n",
       "  643761459391004672,\n",
       "  637540038205640704,\n",
       "  642391653249118208,\n",
       "  643744605754761216,\n",
       "  643732806758203392,\n",
       "  643725728266252288,\n",
       "  637369093776146432,\n",
       "  643723474486325248,\n",
       "  643683477301366784,\n",
       "  641061159811026944,\n",
       "  641030971823890433,\n",
       "  641016589719105536,\n",
       "  641009512955138048,\n",
       "  640991433005010944,\n",
       "  640176871263629312,\n",
       "  640175610313220096,\n",
       "  640166055390879744,\n",
       "  642864464241537024,\n",
       "  642857892018810880,\n",
       "  643865515178500096,\n",
       "  642847395131322368,\n",
       "  642847198129078272,\n",
       "  642846856402325504,\n",
       "  643404192229519360,\n",
       "  643288694808530944,\n",
       "  643166692026224640,\n",
       "  640878038968868864,\n",
       "  639799129116409856,\n",
       "  638385225798676480,\n",
       "  637523928492212224,\n",
       "  638731415178379265,\n",
       "  638433616511565824,\n",
       "  638425880474316800,\n",
       "  643384248775405568,\n",
       "  640548167730221056,\n",
       "  639929780142514177,\n",
       "  639906348528979968,\n",
       "  638007654355484673,\n",
       "  639829828980617216,\n",
       "  643424199416131585,\n",
       "  639768204227776512,\n",
       "  639746839508615169,\n",
       "  643395711711739904,\n",
       "  643395881623023616,\n",
       "  639863808236875776,\n",
       "  639822010638565376,\n",
       "  639804398080774144,\n",
       "  644176448505278464,\n",
       "  644032406530433024,\n",
       "  639577490030227456,\n",
       "  643372485237448704,\n",
       "  643373896654266368,\n",
       "  644218339687051264,\n",
       "  639792286054940672,\n",
       "  639768073013227520,\n",
       "  637086169088552962,\n",
       "  636151302708400128,\n",
       "  636051044355674113,\n",
       "  641309295179599874,\n",
       "  636318644956434433,\n",
       "  643706183363264512,\n",
       "  642996756310044672,\n",
       "  642995945085509632,\n",
       "  642772920524275724,\n",
       "  642773010588540932,\n",
       "  642711199361142784,\n",
       "  639135297721237504,\n",
       "  643588658612801536,\n",
       "  643553362466594822,\n",
       "  643212798659555328,\n",
       "  644297446277955584,\n",
       "  639558016912728064,\n",
       "  644294714703933440,\n",
       "  639537153182179328,\n",
       "  639541283514654720,\n",
       "  643366584107593729,\n",
       "  643364550193115136,\n",
       "  643363715887271936,\n",
       "  643357734461698048,\n",
       "  640838932775727104,\n",
       "  643120445236101121,\n",
       "  643119690223628288,\n",
       "  642419907808899072,\n",
       "  641959458676035584,\n",
       "  641655105243193348,\n",
       "  644163454308352000,\n",
       "  644157131223134208,\n",
       "  644126407858253824,\n",
       "  643343474276831232,\n",
       "  639489242180251649,\n",
       "  639451010407235584,\n",
       "  640158413679427585,\n",
       "  640552745947275264,\n",
       "  639407685251825665,\n",
       "  642342889129922560,\n",
       "  635830012013318146,\n",
       "  642164423000485888,\n",
       "  642163600665247744,\n",
       "  642790137835991040,\n",
       "  639215880879124480,\n",
       "  640838335615926273,\n",
       "  643924473536741376,\n",
       "  638906092781703168,\n",
       "  643903989440991232,\n",
       "  638903373387984897,\n",
       "  639404360213131264,\n",
       "  639403412610805760,\n",
       "  639316983289356288,\n",
       "  639276654213263361,\n",
       "  639226365296967680,\n",
       "  640270399335493632,\n",
       "  639685117015891969,\n",
       "  639524142216310790,\n",
       "  638839741383868416,\n",
       "  639418051700637697,\n",
       "  640907714625990656,\n",
       "  643856874169835525,\n",
       "  639224277070409729,\n",
       "  643749272106725376,\n",
       "  643721596482547712,\n",
       "  639180933271277568,\n",
       "  643575879105441792,\n",
       "  639095443868229632,\n",
       "  638755606124490752,\n",
       "  638685531157757952,\n",
       "  639039587231338496,\n",
       "  643560016633561088,\n",
       "  638668167016001537,\n",
       "  639089185291399168,\n",
       "  643216415135264769,\n",
       "  638361096714330112,\n",
       "  643169533012934662,\n",
       "  640654176645718016,\n",
       "  638250010635857920,\n",
       "  640585037356863488,\n",
       "  640142999465422848,\n",
       "  640142608807907328,\n",
       "  640139300739379200,\n",
       "  639958207222431744,\n",
       "  639855995188084736,\n",
       "  644082028628078592,\n",
       "  639476533812428800,\n",
       "  637747730425741312,\n",
       "  641296203028787200,\n",
       "  641295521320185856,\n",
       "  637557665732907009,\n",
       "  641260028146679809,\n",
       "  637541076300091392,\n",
       "  641279784476114944,\n",
       "  644211074934439936,\n",
       "  644241034587832320,\n",
       "  637532148191395840,\n",
       "  637330701361250304,\n",
       "  644062582463168512,\n",
       "  637241534950305793,\n",
       "  644062845001428993,\n",
       "  637177980700225536,\n",
       "  644064447607242752,\n",
       "  637162257789620224,\n",
       "  643914504045264896,\n",
       "  641025792068218884,\n",
       "  643872716479705088,\n",
       "  643833697712644096,\n",
       "  643559242495078400,\n",
       "  637031181658247168,\n",
       "  640981102551826432,\n",
       "  640969301206376448,\n",
       "  640093950997602304,\n",
       "  640924736285859840,\n",
       "  642703620652314624,\n",
       "  640934432715710465,\n",
       "  640933760066842629,\n",
       "  639352151630827520,\n",
       "  643875108361269248,\n",
       "  640884948862431233,\n",
       "  643855702885289985,\n",
       "  640849361690316800,\n",
       "  643783799021666307,\n",
       "  635971536105684993,\n",
       "  639443672552075264,\n",
       "  639435122895400960,\n",
       "  640266654409191424,\n",
       "  643312238967824384,\n",
       "  643193053860229120,\n",
       "  636572399870328832,\n",
       "  640085576029442048,\n",
       "  638713315632545792,\n",
       "  638665320249565184,\n",
       "  638592163786305536,\n",
       "  638484957925654528,\n",
       "  638650431091122176,\n",
       "  638648212778315776,\n",
       "  636011356421013504,\n",
       "  638644280882503680,\n",
       "  638355194011643904,\n",
       "  638315654291030016,\n",
       "  638314856677044224,\n",
       "  638627451573272576,\n",
       "  640818582885134336,\n",
       "  643832256654655488,\n",
       "  640816240341159936,\n",
       "  639389988870877184,\n",
       "  639345714640867328,\n",
       "  639203322667397124,\n",
       "  639192468207075328,\n",
       "  639186180978933760,\n",
       "  639400845629636608,\n",
       "  639334789007470592,\n",
       "  639146037815476225,\n",
       "  643149904102195201,\n",
       "  643148018670305280,\n",
       "  638048230660550658,\n",
       "  638052493277163521,\n",
       "  637003661923610624,\n",
       "  636885795308208128,\n",
       "  640849271080652800,\n",
       "  640844480233500672,\n",
       "  640842723684163584,\n",
       "  636575087295131649,\n",
       "  643817078122774528,\n",
       "  643816971377713152,\n",
       "  643770648561590272,\n",
       "  642354111770456064,\n",
       "  642112817848582144,\n",
       "  638746894836068352,\n",
       "  639064806272708608,\n",
       "  638993468178739200,\n",
       "  640080552016637952,\n",
       "  642976453563445248,\n",
       "  639109573111095297,\n",
       "  642959103288025088,\n",
       "  642823625628889088,\n",
       "  639069800082358272,\n",
       "  639069796622049280,\n",
       "  642775458061393920,\n",
       "  642752356963196928,\n",
       "  639836543495106560,\n",
       "  642851354038415360,\n",
       "  642811557794160641,\n",
       "  642489578134351872,\n",
       "  642413293836087298,\n",
       "  636551985257250816,\n",
       "  640677134881591296,\n",
       "  636529939941052416,\n",
       "  640620899486597120,\n",
       "  640645210821799936,\n",
       "  643751298488209408,\n",
       "  640683293759963136,\n",
       "  643799533768601600,\n",
       "  642293102359773184,\n",
       "  639942573424017408,\n",
       "  640247606308917248,\n",
       "  640241048866975744,\n",
       "  640783219273674752,\n",
       "  640769699962318848,\n",
       "  640636605498281984,\n",
       "  638428847218786305,\n",
       "  642022922626990080,\n",
       "  641994500446027776,\n",
       "  641781937871421440,\n",
       "  641988915780562944,\n",
       "  641760557457084417,\n",
       "  640577014920036353,\n",
       "  640503723781922817,\n",
       "  640036753366216704,\n",
       "  644064627861622784,\n",
       "  643736807813873664,\n",
       "  640915493721874432,\n",
       "  638236309237178368,\n",
       "  638233608134766592,\n",
       "  638093459254038528,\n",
       "  637932010254782464,\n",
       "  637881564307791872,\n",
       "  638724416474611712,\n",
       "  641678529642561536,\n",
       "  641619189241876480,\n",
       "  640486404221444096,\n",
       "  640487589376618496,\n",
       "  640463182734172160,\n",
       "  640919309007630336,\n",
       "  640648805675847680,\n",
       "  641397851231264768,\n",
       "  641395996438720512,\n",
       "  641360689651580929,\n",
       "  641267955758694400,\n",
       "  639157831464296448,\n",
       "  643716904398491648,\n",
       "  643716148052275200,\n",
       "  639070097227804672,\n",
       "  638918520198295556,\n",
       "  638895184999137280,\n",
       "  643708198415933440,\n",
       "  643704662198194177,\n",
       "  643699149414756352,\n",
       "  643699157753044993,\n",
       "  639429167117942784,\n",
       "  638351581663088641,\n",
       "  638346725195952129,\n",
       "  638343289415016448,\n",
       "  641328291501182976,\n",
       "  641170640960122880,\n",
       "  641168443497017346,\n",
       "  638093605131976705,\n",
       "  640438610165137408,\n",
       "  640328089436708864,\n",
       "  640267184241938433,\n",
       "  640323675326169088,\n",
       "  636154458372747264,\n",
       "  644049095330500608,\n",
       "  643817221043716100,\n",
       "  642957301020815361,\n",
       "  637839194866483200,\n",
       "  643688327850393600,\n",
       "  643499955714441216,\n",
       "  643518583784513536,\n",
       "  643512062597967873,\n",
       "  643508498635091968,\n",
       "  643503790520442881,\n",
       "  643429750321643520,\n",
       "  643192453042835459,\n",
       "  642111077791178752,\n",
       "  642051297135476736,\n",
       "  642401396185276417,\n",
       "  641181024286842880,\n",
       "  642468110004527104,\n",
       "  642459579549356038,\n",
       "  642458845529407488,\n",
       "  640779606069526528,\n",
       "  640077832874422272,\n",
       "  639752775421849600,\n",
       "  639361401484636160,\n",
       "  641966424932679680,\n",
       "  642427531392643072,\n",
       "  642396921353629696,\n",
       "  643549098088505344,\n",
       "  643548596378464256,\n",
       "  643548495497023488,\n",
       "  641777977806729218,\n",
       "  641744692267339776,\n",
       "  641671403499077632,\n",
       "  638682372637114368,\n",
       "  638637405399027713,\n",
       "  638904230196195330,\n",
       "  638611959001300992,\n",
       "  637237109271752704,\n",
       "  630028394802094080,\n",
       "  638575795833671682,\n",
       "  644086314267185152,\n",
       "  642317790960046080,\n",
       "  629687909227098112,\n",
       "  638183437770313728,\n",
       "  642314226804113408,\n",
       "  640582903785721857,\n",
       "  640581254962917377,\n",
       "  640519608840097792,\n",
       "  640517940601847808,\n",
       "  640517771227439104,\n",
       "  640366086903472128,\n",
       "  643527555354640384,\n",
       "  643522118974611456,\n",
       "  641668360820887552,\n",
       "  641662267310927872,\n",
       "  644299856878694400,\n",
       "  641622511780818944,\n",
       "  644299373170552832,\n",
       "  641607511058063360,\n",
       "  639075343240953856,\n",
       "  642160711792205824,\n",
       "  642154967135047680,\n",
       "  639042603045023744,\n",
       "  639784239236521984,\n",
       "  639974049209257984,\n",
       "  639139609125982208,\n",
       "  640321035728998400,\n",
       "  640260634672803840,\n",
       "  641484610002649088,\n",
       "  641680973298540548,\n",
       "  641593184049565696,\n",
       "  641446400023248896,\n",
       "  644141407909773317,\n",
       "  644170903484395520,\n",
       "  644197209748074496,\n",
       "  644216783843397632,\n",
       "  641994532373008384,\n",
       "  641988299192713216,\n",
       "  642340179718610944,\n",
       "  641344946532839424,\n",
       "  641341080609296386,\n",
       "  641227766684368896,\n",
       "  644262701674295296,\n",
       "  641371260421820416,\n",
       "  644166959777513476,\n",
       "  643978993566392324,\n",
       "  642402733484568576,\n",
       "  639884409445859328,\n",
       "  642286451577757696,\n",
       "  639798166855000064,\n",
       "  641775634490990593,\n",
       "  641761959285780483,\n",
       "  642755835433762816,\n",
       "  641908064464076800,\n",
       "  644056858727182336,\n",
       "  634916611477098496,\n",
       "  641735607908237312,\n",
       "  641554859045593088,\n",
       "  639422929080582144,\n",
       "  639400299183099904,\n",
       "  639202751130533888,\n",
       "  641507937588899841,\n",
       "  641151974931607552,\n",
       "  640061788554399744,\n",
       "  643806566534283264,\n",
       "  644186691364876288,\n",
       "  640890543669669889,\n",
       "  644153532690640896,\n",
       "  640801807162343424,\n",
       "  644106001420021761,\n",
       "  640588116315766784,\n",
       "  641641568764592128,\n",
       "  641577577199570944,\n",
       "  644143141453492224,\n",
       "  644112886558797824,\n",
       "  640586742249205760,\n",
       "  640357464177815552,\n",
       "  641159451802796032,\n",
       "  636575811466854400,\n",
       "  636580821978230784,\n",
       "  636675123416813568,\n",
       "  638440869998276609,\n",
       "  639206183006568448,\n",
       "  637099323910692864,\n",
       "  636357533725233152,\n",
       "  636318082764533760,\n",
       "  639169617290768384,\n",
       "  636139605948022786,\n",
       "  639169045946867713,\n",
       "  639122225384280064,\n",
       "  643846994998509572,\n",
       "  643862277125472256,\n",
       "  643861926859177984,\n",
       "  639048742109347841,\n",
       "  638607811895775232,\n",
       "  644285399997747200,\n",
       "  637956584346415104,\n",
       "  643436677529247744,\n",
       "  643425807629725696,\n",
       "  643220484914573312,\n",
       "  643424790557138944,\n",
       "  643421055395172352,\n",
       "  644198662529282048,\n",
       "  644144244911906816,\n",
       "  641056668264955904,\n",
       "  641050836706004993,\n",
       "  636205487567060992,\n",
       "  641244628155367424,\n",
       "  643198856084201472,\n",
       "  635852127156486145,\n",
       "  642511052106792960,\n",
       "  639143531056136192,\n",
       "  643253814867460096,\n",
       "  643207729067257857,\n",
       "  643192443328942080,\n",
       "  643065915651698688,\n",
       "  637041047999238150,\n",
       "  642853772964687872,\n",
       "  642851662017593344,\n",
       "  642706859611152384,\n",
       "  636995050703077376,\n",
       "  636812173302472704,\n",
       "  643761766019780608,\n",
       "  642689823447363584,\n",
       "  641392294378274816,\n",
       "  644083847953563648,\n",
       "  644020476923236352,\n",
       "  643963054317809666,\n",
       "  643943229331775488,\n",
       "  638029262201733125,\n",
       "  636909178070679552,\n",
       "  636644460546424832,\n",
       "  643151354559623168,\n",
       "  643142330929840128,\n",
       "  643141377648406528,\n",
       "  643116814021562368,\n",
       "  643116405651558400,\n",
       "  638720066922631168,\n",
       "  642449359108460544,\n",
       "  643935554837590016,\n",
       "  636798165702852608,\n",
       "  636583160927682560,\n",
       "  636583208637865985,\n",
       "  636429845162033152,\n",
       "  643797085708517380,\n",
       "  643107829214248960,\n",
       "  637872874116788224,\n",
       "  643069688667328516,\n",
       "  643053631848218624,\n",
       "  641773743694475264,\n",
       "  641238358862266369,\n",
       "  643703267168550912,\n",
       "  643621006008057856,\n",
       "  643428520014839809,\n",
       "  643982786316115968,\n",
       "  643954232077512708,\n",
       "  642890147239993344,\n",
       "  642750800268259328,\n",
       "  642825303417597953,\n",
       "  643422486906949632,\n",
       "  643420471921389568,\n",
       "  643279290591760384,\n",
       "  635807653277618176,\n",
       "  634845672743804928,\n",
       "  644196976020615169,\n",
       "  642774411729371139,\n",
       "  642766922237538304,\n",
       "  640325470655934464,\n",
       "  643769903804194816,\n",
       "  643767074200911874,\n",
       "  643149341759287296,\n",
       "  642391815648362496,\n",
       "  643174153768599552,\n",
       "  642678217535565824,\n",
       "  641999535577804801,\n",
       "  641990296230854656,\n",
       "  641990474450927617,\n",
       "  644140899790811136,\n",
       "  643943613597024256,\n",
       "  643770555615711234,\n",
       "  642701597106114560,\n",
       "  642700066344542209,\n",
       "  643576825508065281,\n",
       "  642358834120511492,\n",
       "  637063871849725952,\n",
       "  642655163178741760,\n",
       "  642628394832805888,\n",
       "  642669747134418944,\n",
       "  642660877053886464,\n",
       "  640144570861420544,\n",
       "  639519330527506432,\n",
       "  639514012754018304,\n",
       "  643759250175565824,\n",
       "  642381386754727936,\n",
       "  642383078669815808,\n",
       "  641493069012041728,\n",
       "  640648983422070784,\n",
       "  640626158363656193,\n",
       "  512944579566632961,\n",
       "  638178787469955072,\n",
       "  638013711752540160,\n",
       "  638012270186995713,\n",
       "  639895467887853568,\n",
       "  639880611394646016,\n",
       "  639610960441950208,\n",
       "  644180522848112640,\n",
       "  643974396034588672,\n",
       "  643982919485247488,\n",
       "  637399869443940352,\n",
       "  637038555198550016,\n",
       "  636936375993016320,\n",
       "  636886092030021634,\n",
       "  638469212525199364,\n",
       "  638322573097455616,\n",
       "  639552411162517504,\n",
       "  639535542489772032,\n",
       "  639529078979207168,\n",
       "  636538458757033984,\n",
       "  639238116910452736,\n",
       "  639165525533282304,\n",
       "  644074682090717185,\n",
       "  635802881455718400,\n",
       "  643865801993420804,\n",
       "  635641847935827968,\n",
       "  643308744407912449,\n",
       "  643304529300180992,\n",
       "  643012089024528384,\n",
       "  639147349491773440,\n",
       "  638433662560808961,\n",
       "  638168110512517121,\n",
       "  637785361964498944,\n",
       "  642996171242381312,\n",
       "  637671550913785856,\n",
       "  637657898101932032,\n",
       "  644245244934909952,\n",
       "  641351396114042880,\n",
       "  640563469591400448,\n",
       "  640229647817572352,\n",
       "  640203232871075841,\n",
       "  639097662277615616,\n",
       "  636873952380456961,\n",
       "  644280920896245762,\n",
       "  638812922274254848,\n",
       "  638437614161424384,\n",
       "  637897615498182656,\n",
       "  636908327067353088,\n",
       "  636612783791034368,\n",
       "  636308947163578368,\n",
       "  638405943278092289,\n",
       "  643906001960325123,\n",
       "  237667771868143616,\n",
       "  638319443676782592,\n",
       "  641336484553977856,\n",
       "  644307939759628288,\n",
       "  640901086409302016,\n",
       "  641169136077438976,\n",
       "  641168443211915264,\n",
       "  641143458435080192,\n",
       "  639092360354336768,\n",
       "  643794549647781889,\n",
       "  643787579226226688,\n",
       "  641680404236345344,\n",
       "  644307659970203648,\n",
       "  643887240511365120,\n",
       "  640898095585361920,\n",
       "  641236138250907648,\n",
       "  640995492764106752,\n",
       "  640971327374012418,\n",
       "  640964784003895297,\n",
       "  640954708639674369,\n",
       "  644263933730095104,\n",
       "  641672042543230976,\n",
       "  642488400688345088,\n",
       "  641302909058215936,\n",
       "  643471553699684354,\n",
       "  639493061714780166,\n",
       "  641238590308155392,\n",
       "  641225995786305536,\n",
       "  641366423621603329,\n",
       "  641218820410077184,\n",
       "  641218704794087425,\n",
       "  641348281109352449,\n",
       "  641343118768345088,\n",
       "  641196871990538241,\n",
       "  641330062466355200,\n",
       "  630325616328450048,\n",
       "  641461903269756928,\n",
       "  638842278942011393,\n",
       "  638699381865246721,\n",
       "  641453935958564864,\n",
       "  641446939901460480,\n",
       "  642465223996252160,\n",
       "  642037308846403585,\n",
       "  641289676821798912,\n",
       "  641287446571913216,\n",
       "  641284898712588288,\n",
       "  641786216308961280,\n",
       "  642058187659694081,\n",
       "  641970718033453056,\n",
       "  641752644764237824,\n",
       "  636618130261995521,\n",
       "  637399474839646208,\n",
       "  636339668821409792,\n",
       "  636895463812296704,\n",
       "  641706432816025601,\n",
       "  640847511566057472,\n",
       "  640845677799546880,\n",
       "  641677419104051200,\n",
       "  641676599977476096,\n",
       "  641670137570009088,\n",
       "  641948472120377344,\n",
       "  641731674485731328,\n",
       "  640991744339910656,\n",
       "  641706776103112704,\n",
       "  641657235437920256,\n",
       "  ...])"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_samples.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "616"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onehot(user_id):\n",
    "    v = np.zeros(len(g.vs))\n",
    "    ind = g.vs['twid'].index(str(user_id))\n",
    "    v[ind] = 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_onehot(neighbour_ids[20]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación más sencilla\n",
    "\n",
    "- sin embeddings\n",
    "- sólo el vecindario de u\n",
    "- features: is_u, is_rt, centralidades (misma info que paper anterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pyg_data_objects(tweet_ids, user_id, neighbour_users):\n",
    "    '''\n",
    "        Given tweets, central user and neighbour_users,\n",
    "        we extract a pytorchgeometric Data representation\n",
    "        of the 'neighbour activity' for each tweet\n",
    "        \n",
    "        nodes = user + retweeting neighbors + other neighbors\n",
    "        features:\n",
    "            centralities\n",
    "            is_central_user\n",
    "            is_retweeting\n",
    "    '''\n",
    "    s = open_session()\n",
    "    user = s.query(User).get(user_id)\n",
    "\n",
    "    ### Compute index mappings (igraph, twid, row_id)\n",
    "\n",
    "    # print(\"# Filter centralities to cover only ngids\")\n",
    "    # This is the fixed order we will keep for nodes in x,\n",
    "    # for all the generated datasamples for this central user\n",
    "    user_id = user.id\n",
    "    neighbour_ids = [u.id for u in neighbour_users]    \n",
    "    index_users = [user] + neighbour_users\n",
    "    index_twid = [user_id] + neighbour_ids    \n",
    "    index_twid_to_igraph_map = {int(l): i for (i,l) in enumerate(g.vs[\"twid\"]) if int(l) in index_twid}\n",
    "    index_ig = [index_twid_to_igraph_map[l] for l in index_twid]\n",
    "    index_centralities = [np.array(m)[index_ig] for m in centralities]\n",
    "\n",
    "    ### Compute fixed centrality features\n",
    "    centralities_matrix = np.vstack(index_centralities).transpose()\n",
    "\n",
    "    is_central_col = np.zeros(len(index_users))\n",
    "    is_central_col[0] = 1\n",
    "    is_central_col = np.expand_dims(is_central_col, axis=1)\n",
    "\n",
    "    ## Compute edges\n",
    "    # select edgeds within subgraph\n",
    "    edges = g.es.select(_within=index_ig)\n",
    "    edges_igraph = [e.tuple for e in edges]\n",
    "\n",
    "    # now we need to map them to row indices in the x feature matrix\n",
    "    # igraph_ind -> tw_ind -> row_ind\n",
    "\n",
    "    igraph_ind_to_tw_ind_map = {ig: tw for (tw, ig) in index_twid_to_igraph_map.items()}\n",
    "    tw_ind_to_row_ind_map = {tw: i for (i, tw) in enumerate(index_twid)}\n",
    "    def map_ig_ind_to_row_ind(ig):\n",
    "        return tw_ind_to_row_ind_map[igraph_ind_to_tw_ind_map[ig]]\n",
    "\n",
    "    def map_edge(e):\n",
    "        a, b = e\n",
    "        return (map_ig_ind_to_row_ind(a), map_ig_ind_to_row_ind(b))\n",
    "    \n",
    "    edge_index = torch.tensor([map_edge(e) for e in edges_igraph])\n",
    "    edge_index = edge_index.transpose(0,1)\n",
    "\n",
    "    ### Compute retweeting features for each example\n",
    "    data_objects = []\n",
    "    for tweet_id in tweet_ids:\n",
    "        is_retweeting_col = np.zeros(len(index_users))\n",
    "        for i, u in enumerate(index_users):\n",
    "            if tweet_id in [t.id for t in u.timeline]:\n",
    "                is_retweeting_col[i] = 1\n",
    "        is_retweeting_col = np.expand_dims(is_retweeting_col, axis=1)\n",
    "\n",
    "        x = np.hstack([centralities_matrix, is_central_col, is_retweeting_col])\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        y = torch.tensor(int(tweet_id in [t.id for t in user.timeline]), dtype=torch.long)\n",
    "        \n",
    "        d = Data(x=x, edge_index=edge_index, y=y)\n",
    "        data_objects.append(d)\n",
    "        \n",
    "    return data_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_to_data_objects(samples):\n",
    "    data_objects = []\n",
    "    s = open_session()\n",
    "\n",
    "    for user_id, tweet_ids in list(samples.items())[:4]:\n",
    "        print(user_id)\n",
    "        user = s.query(User).get(user_id)\n",
    "        neighbours = get_level2_neighbours(user, s)\n",
    "        # remove central user from neighbours\n",
    "        neighbour_users = [u for u in neighbours if u.id != user.id]\n",
    "        data_objects += create_pyg_data_objects(tweet_ids[:200], user_id, neighbour_users)\n",
    "    return data_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781293\n",
      "148887961\n",
      "273744824\n",
      "206106207\n"
     ]
    }
   ],
   "source": [
    "train_data_objects = samples_to_data_objects(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1493451997\n",
      "20182089\n",
      "10012122\n",
      "117251043\n"
     ]
    }
   ],
   "source": [
    "test_data_objects = samples_to_data_objects(test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-FO5xL3mw98"
   },
   "source": [
    "# Graph Classification with Graph Neural Networks\n",
    "\n",
    "[Previous: Node Classification with Graph Neural Networks](https://colab.research.google.com/drive/14OvFnAXggxB8vM4e8vSURUp1TaKnovzX)\n",
    "\n",
    "In this tutorial session we will have a closer look at how to apply **Graph Neural Networks (GNNs) to the task of graph classification**.\n",
    "Graph classification refers to the problem of classifiying entire graphs (in contrast to nodes), given a **dataset of graphs**, based on some structural graph properties.\n",
    "Here, we want to embed entire graphs, and we want to embed those graphs in such a way so that they are linearly separable given a task at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j11WiUr-PRH_",
    "outputId": "5f84abf9-05bc-4c62-95f1-5f80b603b0f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 800\n",
      "Number of test graphs: 800\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(12345)\n",
    "\n",
    "train_dataset = train_data_objects\n",
    "test_dataset = test_data_objects\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0gZ-l0npPIca",
    "outputId": "65b6d684-0e67-42f3-bf60-c98ec1d7338a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[36086, 7], edge_index=[2, 1173141], y=[64], batch=[36086], ptr=[65])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[37483, 7], edge_index=[2, 1228717], y=[64], batch=[37483], ptr=[65])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[35494, 7], edge_index=[2, 1152682], y=[64], batch=[35494], ptr=[65])\n",
      "\n",
      "Step 4:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[36972, 7], edge_index=[2, 1254876], y=[64], batch=[36972], ptr=[65])\n",
      "\n",
      "Step 5:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[38426, 7], edge_index=[2, 1304534], y=[64], batch=[38426], ptr=[65])\n",
      "\n",
      "Step 6:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[37364, 7], edge_index=[2, 1249450], y=[64], batch=[37364], ptr=[65])\n",
      "\n",
      "Step 7:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[36439, 7], edge_index=[2, 1213035], y=[64], batch=[36439], ptr=[65])\n",
      "\n",
      "Step 8:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[36971, 7], edge_index=[2, 1232845], y=[64], batch=[36971], ptr=[65])\n",
      "\n",
      "Step 9:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[37616, 7], edge_index=[2, 1218788], y=[64], batch=[37616], ptr=[65])\n",
      "\n",
      "Step 10:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[38483, 7], edge_index=[2, 1298616], y=[64], batch=[38483], ptr=[65])\n",
      "\n",
      "Step 11:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[35834, 7], edge_index=[2, 1203803], y=[64], batch=[35834], ptr=[65])\n",
      "\n",
      "Step 12:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[36158, 7], edge_index=[2, 1200058], y=[64], batch=[36158], ptr=[65])\n",
      "\n",
      "Step 13:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(x=[18674, 7], edge_index=[2, 627055], y=[32], batch=[18674], ptr=[33])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "for step, data in enumerate(train_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pq-VyzUwPpw"
   },
   "source": [
    "## Training a Graph Neural Network (GNN)\n",
    "\n",
    "Training a GNN for graph classification usually follows a simple recipe:\n",
    "\n",
    "1. Embed each node by performing multiple rounds of message passing\n",
    "2. Aggregate node embeddings into a unified graph embedding (**readout layer**)\n",
    "3. Train a final classifier on the graph embedding\n",
    "\n",
    "There exists multiple **readout layers** in literature, but the most common one is to simply take the average of node embeddings:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{\\mathcal{G}} = \\frac{1}{|\\mathcal{V}|} \\sum_{v \\in \\mathcal{V}} \\mathcal{x}^{(L)}_v\n",
    "$$\n",
    "\n",
    "PyTorch Geometric provides this functionality via [`torch_geometric.nn.global_mean_pool`](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.glob.global_mean_pool), which takes in the node embeddings of all nodes in the mini-batch and the assignment vector `batch` to compute a graph embedding of size `[batch_size, hidden_channels]` for each graph in the batch.\n",
    "\n",
    "The final architecture for applying GNNs to the task of graph classification then looks as follows and allows for complete end-to-end training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 703,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_node_features = x.shape[1]\n",
    "num_node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CN3sRVuaQ88l",
    "outputId": "59c998ba-b387-4413-d7d3-2101a27495bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(7, 5)\n",
      "  (conv2): GCNConv(5, 5)\n",
      "  (conv3): GCNConv(5, 5)\n",
      "  (lin): Linear(in_features=5, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):        \n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=5)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2Q37tbHyQ6A"
   },
   "source": [
    "Here, we again make use of the [`GCNConv`](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv) with $\\mathrm{ReLU}(x) = \\max(x, 0)$ activation for obtaining localized node embeddings, before we apply our final classifier on top of a graph readout layer.\n",
    "\n",
    "Let's train our network for a few epochs to see how well it performs on the training as well as test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "HvhgQoO8Svw4",
    "outputId": "4d17af35-85c8-4bcd-8e16-c514fd2ff714"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.9812, Test Acc: 0.9675\n",
      "Epoch: 002, Train Acc: 0.9812, Test Acc: 0.9675\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Javascript\n",
    "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "         out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "         loss = criterion(out, data.y)  # Compute the loss.\n",
    "         loss.backward()  # Derive gradients.\n",
    "         optimizer.step()  # Update parameters based on gradients.\n",
    "         optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "     model.eval()\n",
    "\n",
    "     correct = 0\n",
    "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "         out = model(data.x, data.edge_index, data.batch)  \n",
    "         pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "         correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "     return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "for epoch in range(1, 3):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"ggn-model.torch\"\n",
    "torch.save(model, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(MODEL_PATH)\n",
    "\n",
    "preds = []\n",
    "labels = []\n",
    "for data in test_loader:\n",
    "    out = model(data.x, data.edge_index, data.batch)  \n",
    "    preds += out.argmax(dim=1)  # Use the class with highest probability.\n",
    "    labels += data.y\n",
    "\n",
    "f1_score(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       774\n",
      "           1       0.00      0.00      0.00        26\n",
      "\n",
      "    accuracy                           0.97       800\n",
      "   macro avg       0.48      0.50      0.49       800\n",
      "weighted avg       0.94      0.97      0.95       800\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcelayes/miniconda3/envs/sna/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/pcelayes/miniconda3/envs/sna/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/pcelayes/miniconda3/envs/sna/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "sna",
   "language": "python",
   "name": "sna"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
